{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a98b2312-4d56-4c41-9d15-d602871e111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import pyttsx3\n",
    "import datetime\n",
    "import webbrowser\n",
    "import wikipedia\n",
    "import os\n",
    "import speech_recognition as sr\n",
    "import cv2\n",
    "import pytesseract\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "699bea5d-074e-414b-a928-f12c76820770",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the path to the Tesseract executable\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55470057-4785-4529-9a5e-84196c8e5775",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize text-to-speech engine\n",
    "engine = pyttsx3.init('sapi5')\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voice', voices[1].id)\n",
    "engine.setProperty('rate', 150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f997f5f-8145-45c6-9a06-126a0b303edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize speech recognizer\n",
    "recognizer = sr.Recognizer()\n",
    "microphone = sr.Microphone()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da9e0a08-abf9-47eb-97c4-61f9daf57af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate 200 sample texts\n",
    "sample_texts = [\n",
    "    \"open youtube\",\n",
    "    \"open google\",\n",
    "    \"play music\",\n",
    "    \"open gmail\",\n",
    "    \"open whatsapp\",\n",
    "    \"tell me the time\",\n",
    "    \"tell me the date\",\n",
    "    \"search Wikipedia\",\n",
    "    \"open camera\",\n",
    "    \"stop\"\n",
    "] * 20  # Repeat the list 20 times to get 200 samples\n",
    "\n",
    "# Generate labels accordingly\n",
    "labels = [i for i in range(10)] * 20  # Assuming 10 labels, repeated 20 times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d17cee72-0db0-4f65-b747-9d05d676e081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Vectorize the sample texts\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(sample_texts)\n",
    "\n",
    "# Train Random Forest classifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(X, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d9a6a84-12e1-4f75-9cc0-2d3d2e728fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def speak(audio):\n",
    "    \"\"\"Convert text to speech.\"\"\"\n",
    "    engine.say(audio)\n",
    "    engine.runAndWait()\n",
    "\n",
    "def greet():\n",
    "    \"\"\"Greet the user based on the time of the day.\"\"\"\n",
    "    hour = int(datetime.datetime.now().hour)\n",
    "    if hour >= 0 and hour < 12:\n",
    "        speak(\"Good Morning!\")\n",
    "    elif hour >= 12 and hour < 18:\n",
    "        speak(\"Good Afternoon!\")\n",
    "    else:\n",
    "        speak(\"Good Evening!\")\n",
    "    speak(\"Welcome, I am your personal assistant. How can I assist you today?\")\n",
    "\n",
    "def recognize_speech():\n",
    "    \"\"\"Recognize speech using the microphone.\"\"\"\n",
    "    with microphone as source:\n",
    "        speak(\"I am listening...\")\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        audio = recognizer.listen(source)\n",
    "    try:\n",
    "        speak(\"Recognizing...\")\n",
    "        text = recognizer.recognize_google(audio, language=\"en-IN\")\n",
    "        print(\"Recognized Text:\", text)  # Print recognized text\n",
    "        return text.lower()\n",
    "    except sr.RequestError:\n",
    "        speak(\"Sorry, I couldn't reach the Google API.\")\n",
    "    except sr.UnknownValueError:\n",
    "        speak(\"Sorry, I could not understand the audio.\")\n",
    "        return \"\"\n",
    "    return \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c97650d0-7b1f-4cc8-b5dd-df380091170a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_action(command):\n",
    "    \"\"\"Perform the action based on the command.\"\"\"\n",
    "    command_features = vectorizer.transform([command])\n",
    "    predicted_label = classifier.predict(command_features)[0]\n",
    "    print(\"Voice Command:\", command)  # Print voice command\n",
    "    if predicted_label == 0:\n",
    "        speak(\"Opening YouTube\")\n",
    "        webbrowser.open(\"https://www.youtube.com/\")\n",
    "    elif predicted_label == 1:\n",
    "        speak(\"Opening Google\")\n",
    "        webbrowser.open(\"https://www.google.co.in/\")\n",
    "    elif predicted_label == 2:\n",
    "        speak(\"Opening music player...\")\n",
    "        os.startfile(\"C:\\\\Program Files (x86)\\\\Windows Media Player\\\\wmplayer.exe\")\n",
    "    elif predicted_label == 3:\n",
    "        speak(\"Opening Gmail\")\n",
    "        webbrowser.open(\"https://mail.google.com/mail/u/0/#inbox\")\n",
    "    elif predicted_label == 4:\n",
    "        speak(\"Opening WhatsApp\")\n",
    "        webbrowser.open(\"https://web.whatsapp.com/\")\n",
    "    elif predicted_label == 5:\n",
    "        speak(f\"The time is {datetime.datetime.now().strftime('%I:%M %p')}\")\n",
    "    elif predicted_label == 6:\n",
    "        speak(f\"Today's date is {datetime.datetime.now().strftime('%A, %B %d, %Y')}\")\n",
    "    elif predicted_label == 7:\n",
    "        speak(\"What do you want to search on Wikipedia?\")\n",
    "        search_query = recognize_speech()\n",
    "        if search_query:\n",
    "            speak(\"Searching Wikipedia...\")\n",
    "            try:\n",
    "                result = wikipedia.summary(search_query, sentences=2)\n",
    "                speak(\"According to Wikipedia,\")\n",
    "                speak(result)\n",
    "            except wikipedia.exceptions.WikipediaException:\n",
    "                speak(\"Sorry, I couldn't find information on that topic.\")\n",
    "    elif predicted_label == 8:\n",
    "        speak(\"Opening Camera...\")\n",
    "        open_webcam()\n",
    "    elif predicted_label == 9:\n",
    "        speak(\"Thank you. Bye. Have a nice day.\")\n",
    "        root.destroy()\n",
    "    else:\n",
    "        speak(\"Sorry, I didn't understand that command. Please try again.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a6e93b6-deef-4401-bc9a-e74781605cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def open_webcam():\n",
    "    \"\"\"Capture an image from the webcam and return it.\"\"\"\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        speak(\"Could not open webcam.\")\n",
    "        return None\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "    if ret:\n",
    "        img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        img.show()  # Display the captured image\n",
    "        text = extract_text_from_image(img)\n",
    "        if text:\n",
    "            speak(f\"The extracted text is: {text}\")\n",
    "        else:\n",
    "            speak(\"No text found in the image.\")\n",
    "        print(\"Extracted Text:\", text)  # Print the extracted text for debugging\n",
    "\n",
    "def extract_text_from_image(img):\n",
    "    \"\"\"Extract text from an image using OCR.\"\"\"\n",
    "    gray = img.convert('L')  # Convert image to grayscale\n",
    "    text = pytesseract.image_to_string(gray)\n",
    "    return text\n",
    "\n",
    "def on_voice_command_button():\n",
    "    greet()  # Greet the user before listening for commands\n",
    "    command = recognize_speech()\n",
    "    if command:\n",
    "        update_text_label(command)  # Update label with recognized text\n",
    "        perform_action(command)\n",
    "    else:\n",
    "        speak(\"I didn't catch that. Could you please repeat?\")\n",
    "\n",
    "def create_big_circle_button(root):\n",
    "    circle_button = tk.Button(root, text=\"Speak\", bg=\"blue\", fg=\"white\", font=(\"Helvetica\", 24), command=on_voice_command_button)\n",
    "    circle_button.place(relx=0.5, rely=0.5, anchor=tk.CENTER)\n",
    "\n",
    "def on_upload_button():\n",
    "    filepath = filedialog.askopenfilename(filetypes=[(\"Image Files\", \".png;.jpg;.jpeg;.bmp\")])\n",
    "    if filepath:\n",
    "        img = Image.open(filepath)\n",
    "        img.show()  # Display the uploaded image\n",
    "        text = extract_text_from_image(img)\n",
    "        if text:\n",
    "            speak(f\"The extracted text is: {text}\")\n",
    "        else:\n",
    "            speak(\"No text found in the image.\")\n",
    "        print(\"Extracted Text:\", text)  # Print the extracted text for debugging\n",
    "\n",
    "def on_webcam_button():\n",
    "    open_webcam()\n",
    "\n",
    "def update_text_label(text):\n",
    "    \"\"\"Update the text label with the recognized text.\"\"\"\n",
    "    text_label.config(text=f\"Recognized Text: {text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db88087c-6123-4a6a-8cd4-f505a2e5ce22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"Smart text reader\")\n",
    "root.geometry(\"400x300\")\n",
    "\n",
    "text_label = tk.Label(root, text=\"\", font=(\"Helvetica\", 12))\n",
    "text_label.pack()\n",
    "\n",
    "upload_button = tk.Button(root, text=\"Upload Image\", command=on_upload_button)\n",
    "upload_button.pack(pady=5)\n",
    "\n",
    "webcam_button = tk.Button(root, text=\"Open Webcam\", command=on_webcam_button)\n",
    "webcam_button.pack(pady=5)\n",
    "\n",
    "create_big_circle_button(root)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdc0ae8-c5bb-46c7-a980-2af630dc9bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
